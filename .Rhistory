data=read.table("clipboard",header = t)
install.packages("psych")
library(psych)
library(psych)
data=read.table("clipboard",header=T)
head(data)
class(data)
a<-sum(data$专家-data$结果)^2/50
a
hotel=read.table("clipboard",header = T)
head(hotel)
b<-sum(hotel$结果-hotel$专家)^2/50
b
hotel<-read.table("clipboard",header = T)
b<-sum(hotel$结果-hotel$专家)^2/50
b
hotel<-read.table("clipboard",header=T)
b<-sum(hotel$结果-hotel$专家)^2/50
b
hotel<-read.table("clipboard",heder=T)
hotel<-read.table("clipboard",header = t)
sum(hotel$结果-hotel$专家)^2/50
hotel<-read.table("clipboard",header = T)
sum(hotel$结果-hotel$专家)^2/50
hotel<-read.table("clipboard",header = T)
sum(hotel$结果-hotel$专家)^2/50
data<-read.table("clipboard",header=T)
(sum(data$结果-data$专家)^2)/50
(sum(hotel$结果-hotel$专家)^2)/50
setwd(dir="C:/Users/18356/Desktop/Kaggle/Give Me Some Credit/GiveMeSomeCredit")
getwd()
credit_data<-read.csv('cs-training.csv')
class(credit_data)  #导入数据，并查看数据类型
credit_data <- read.csv('cs-training.csv',stringsAsFactors = FALSE)
class(credit_data)  #导入数据，并且查看数据结构，stringAsFactors=FALSE查阅网站：最好一直加上这个条件
head(credit_data)
str(credit_data)  #显示数据结构
cr_data<-credit_data[,2:12]  #去除索引列
names(cr_data)<c('y','x1','x2','x3','x4','x5','x6','x7','x8','x9','x10')  #将每个属性重新命名
head(cr_data)
names(cr_data)<-c('y','x1','x2','x3','x4','x5','x6','x7','x8','x9','x10')  #将每个属性重新命名
head(cr_data)
#y表示逾期未还款，所给数据中1表示违约，0表示未违约，但是按所给数据分析所得结果会造成分数与该值呈现负相关，所以为了便于后续分析，将y做变换，使得1表示未违约，0表示违约
cr_data$y<-1-cr_data$y  #变换
#查看数据发现数据中有不少缺失值，下面开始处理缺失值
#此处要用到VIM包和mice包
#VIM包中的matrixplot函数可以将数据集中的缺失数据以可视化的方式显示出来,在本例中红色表示缺失值,颜色越深表示缺失值越多
#mice包中的mice.pattern()函数生成一个数据框来展示缺失值的个数
install.packages('VIM')  #安装包
install.packages('mice')
matrixplot(cr_data)  #绘制缺失值图
matrix(cr_data)
library(VIM)
matrixplot(cr_data)
#生成了缺失值图像，记得在使用包中函数前要先library()该包
library(mice)
md.pattern(cr_data)  #生成数据框，展示缺失值个数
#以上结果表明，有120269条数据正常，25807条数据中x5缺失，3924条数据中x10和x5同时缺失，有33655条数据存在各种缺失情况，1表示正常，0表示缺失
install.packages('ggplot2')
library(ggplot2)
ggplot(data = cr_data,age(x5)+geom_density(fill="lightskyblue")+xlim(0,25000)+geom_vline(aes(xintercept=median(cr_data$x5[!is.na(cr_data$x5)])),colour="red",linetype="dashed",lwd=1))
ggplot(data = cr_data,aes(x5)+geom_density(fill="lightskyblue")+xlim(0,25000)+geom_vline(aes(xintercept=median(cr_data$x5[!is.na(cr_data$x5)])),colour="red",linetype="dashed",lwd=1))
ggplot(data = cr_data,aes(x5))+geom_density(fill="lightskyblue")+xlim(0,25000)+geom_vline(aes(xintercept=median(cr_data$x5[!is.na(cr_data$x5)])),colour="red",linetype="dashed",lwd=1)
#关于上述函数的详细解释：
#1.ggplot，geom_：图形类型：geom_density()：密度曲线所使用的图层函数，fill：填充效果，geom_vline：添加线linetype='dashed'为虚线，is.na(cr_data$x5)：判断数据中缺失值是否存在，median()：计算平均值，计算x5中缺失值的平均个数
#该代码中选择用中位数填充缺失值，百度搜索不同情况下该用哪些方法填充缺失值
cr_data$x5[is.na(cr_data$x5)]=median(cr_data$x5[!is.na(cr_data$x5)])  #用x5的平均值填充缺失值
#由图像发现，x5的分布图像的大部分数据值与x5的平均值相近，所以使用平均值进行填充
#由于x10的缺失值数量所占比重较小，所以直接删除
cr_data<-na.omit(cr_data)  #na.omit()删除返回值为缺失值的数据
#缺失值处理完毕，开始处理异常值
#百度异常值的种类以及处理方法
boxplot(cr_data$x2)
#申请信用卡的年龄应为18~65，所以删除该范围之外的数据
cr_data<-cr_data[cr_data$x2<=65&cr_data$x2>=18,]
boxplot.stats(cr_data$x2)
#boxplot.stats()：实现单变量检测，$stats：依次显示最小值、下四分位数、中位数、上四分位数以及最大值
$n：显示共n个统计量
$conf：显示95%的置信区间
$out：显示异常值
#boxplot.stats()：实现单变量检测，$stats：依次显示最小值、下四分位数、中位数、上四分位数以及最大值，$n：显示共n个统计量，$conf：显示95%的置信区间，$out：显示异常值
boxplot(cr_data)
#处理x3,x7,x9的异常值
boxplot(cr_data$x3,cr_data$x7,cr_data$x9)
#由图像得异常值均为接近100的数据
unique(cr_data$x3)
unique(cr_data$x7)
unique(cr_data$x9)
cr_data<-cr_data[-which(cr_data$x3==96),]
#unique()：返回数据中的所有数，遇到重复数值只保留第一个
unique(cr_data$x3)
cr_data<-cr_data[-which(cr_data$x3==98),]
unique(cr_data$x7)
unique(cr_data$x9)
#可以看出异常值已被剔除
#建模前的准备：1.变量之间的相关性分析
library()
install.packages('corrplot')
library(corrplot)
cor1<-cor(cr_data)  #相关系数计算
corrplot(cor1,method = 'number')   #绘制相关系数图
#以数的形式体现
#由图可知，各个自变量之间相关性很弱，可以初步判断存在多重共线性，但是在建模之后可以用VIF来检验多重共线性，来确保模型拟合程度较好。
#当存在多重共线性时，需要对数据进行降维或者剔除处理，百度查询
#切分数据集
table(cr_data$y)
#可以看出y存在失衡问题，0所占比重过小，如何对非平衡数据进行处理？（百度查询），smote算法
install.packages("caret")
library(caret)
set.seed(500)
#set.seed()，该命令的作用是设定生成随机数的种子，种子是为了让结果具有重复性。如果不设定种子，生成的随机数无法重现。目的：是让我的模拟能够可重复出现，因为很多时候我们需要取随机数，但这段代码再跑一次的时候，结果就不一样了，如果需要重复出现同样的模拟结果的话，就可以用set.seed()。set.seed(100)不应将括号里的数字理解成“一百”，而是应该理解成“编号为一零零的随机数发生”，下一次再模拟可以采用二零零（200）或者一一一（111）等不同的编号即可，编号设定基本可以随意。
splitindex<-createDataPartition(cr_data$y,times = 1,p=0.5,list = FALSE)
#创建平衡数据的分割，times：创建分区的数目，p：用于训练的数据百分比，list：若为TRUE则返回值为列表
traindata<-cr_data[splitindex,]
class(splitindex)
testdata<-cr_data[-splitindex,]
prop.table(table(traindata$y))
head(splitindex)
head(traindata)
prop.table(table(testdata$y))
#建模分析
fit<-glm(y~.,data=traindata,family = 'binomial')  #Logistic回归，family=binomial：变量服从二项分布
it=glm(y~.,data=traindata,family = "binomial")
fit=glm(y~.,data=traindata,family = "binomial")
summary(fit)
#变量x1,x4,x6对y的影响不显著，所以可直接删除
fit2 <- glm(y~x2+x3+x5+x7+x8+x9+x10,data=traindata,family = "binomial")
summary(fit2)
#模型评估
install.packages('pROC')
install.packages("pROC")
pre<-predict(fit2,testdata)
library(pROC)
modelroc<-roc(testdata$y,pre)
plot(modelroc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
+      grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE)
plot(modelroc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),grid.col=c("green", "red"), max.auc.polygon=TRUE,auc.polygon.col="skyblue", print.thres=TRUE)
#补充介绍WOE转换：将logistic回归模型转化为标准评分卡格式
cutx2<-c(-Inf,25,30,35,40,45,50,55,60,65)
plot(cut(traindata$x2,cutx2))
agelessthan<-getwoe(traindata$x2,-Inf,30)
